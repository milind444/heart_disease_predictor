{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f339562c",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3968718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf41da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets_4123_6408_framingham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5278fcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2354bd",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ec296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31eba2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9bbf6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6fa7ca",
   "metadata": {},
   "source": [
    "# Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962e496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the binary columns\n",
    "bin_cols = [\"male\", \"currentSmoker\", \"prevalentStroke\", \"prevalentHyp\", \"diabetes\"]\n",
    "\n",
    "# Fill missing values for binary features with the most frequent value (mode)\n",
    "for col in bin_cols:\n",
    "    mode_val = df[col].mode()[0]\n",
    "    df.fillna({col: mode_val}, inplace=True)\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "missing_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de8c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "# Fill missing values for numeric features\n",
    "numeric_cols = [\"cigsPerDay\", \"BPMeds\", \"totChol\", \"BMI\", \"heartRate\", \"glucose\"]\n",
    "for col in numeric_cols:\n",
    "    median_val = df[col].median()\n",
    "    df.fillna({col: median_val}, inplace=True)\n",
    "\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "missing_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a5140c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61c7cf12",
   "metadata": {},
   "source": [
    "# Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c06bb283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenYearCHD\n",
       "0    3596\n",
       "1     644\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TenYearCHD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "582bf290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df['TenYearCHD'] == 0]\n",
    "df_minority = df[df['TenYearCHD'] == 1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # Sample with replacement\n",
    "                                 n_samples=len(df_majority),    # To match majority class\n",
    "                                 random_state=42) # Reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "037d59a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenYearCHD\n",
       "0    3596\n",
       "1    3596\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['TenYearCHD'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bbf299",
   "metadata": {},
   "source": [
    "# Train Test Split and Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845d95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df_balanced.drop(columns=['TenYearCHD'])\n",
    "y = df_balanced['TenYearCHD']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c6809b",
   "metadata": {},
   "source": [
    "# Scaling (StandardScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9cd6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler to training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8dcb35",
   "metadata": {},
   "source": [
    "# Training 10 Models With Different Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcd75f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: xgboost in c:\\users\\nofes\\appdata\\roaming\\python\\python313\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "RandomForestClassifier Accuracy: 0.9680333564975677\n",
      "Classification Report for RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       735\n",
      "           1       0.94      0.99      0.97       704\n",
      "\n",
      "    accuracy                           0.97      1439\n",
      "   macro avg       0.97      0.97      0.97      1439\n",
      "weighted avg       0.97      0.97      0.97      1439\n",
      "\n",
      "Confusion Matrix for RandomForestClassifier:\n",
      "[[694  41]\n",
      " [  5 699]]\n",
      "==================================================\n",
      "AdaBoostClassifier Accuracy: 0.6518415566365532\n",
      "Classification Report for AdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64       735\n",
      "           1       0.63      0.70      0.66       704\n",
      "\n",
      "    accuracy                           0.65      1439\n",
      "   macro avg       0.65      0.65      0.65      1439\n",
      "weighted avg       0.65      0.65      0.65      1439\n",
      "\n",
      "Confusion Matrix for AdaBoostClassifier:\n",
      "[[447 288]\n",
      " [213 491]]\n",
      "==================================================\n",
      "GradientBoostingClassifier Accuracy: 0.7289784572619875\n",
      "Classification Report for GradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72       735\n",
      "           1       0.70      0.77      0.74       704\n",
      "\n",
      "    accuracy                           0.73      1439\n",
      "   macro avg       0.73      0.73      0.73      1439\n",
      "weighted avg       0.73      0.73      0.73      1439\n",
      "\n",
      "Confusion Matrix for GradientBoostingClassifier:\n",
      "[[508 227]\n",
      " [163 541]]\n",
      "==================================================\n",
      "LogisticRegression Accuracy: 0.6587908269631688\n",
      "Classification Report for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       735\n",
      "           1       0.65      0.66      0.66       704\n",
      "\n",
      "    accuracy                           0.66      1439\n",
      "   macro avg       0.66      0.66      0.66      1439\n",
      "weighted avg       0.66      0.66      0.66      1439\n",
      "\n",
      "Confusion Matrix for LogisticRegression:\n",
      "[[481 254]\n",
      " [237 467]]\n",
      "==================================================\n",
      "SVC Accuracy: 0.6831132731063239\n",
      "Classification Report for SVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68       735\n",
      "           1       0.67      0.70      0.68       704\n",
      "\n",
      "    accuracy                           0.68      1439\n",
      "   macro avg       0.68      0.68      0.68      1439\n",
      "weighted avg       0.68      0.68      0.68      1439\n",
      "\n",
      "Confusion Matrix for SVC:\n",
      "[[493 242]\n",
      " [214 490]]\n",
      "==================================================\n",
      "KNeighborsClassifier Accuracy: 0.7873523280055594\n",
      "Classification Report for KNeighborsClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.66      0.76       735\n",
      "           1       0.72      0.92      0.81       704\n",
      "\n",
      "    accuracy                           0.79      1439\n",
      "   macro avg       0.81      0.79      0.78      1439\n",
      "weighted avg       0.81      0.79      0.78      1439\n",
      "\n",
      "Confusion Matrix for KNeighborsClassifier:\n",
      "[[482 253]\n",
      " [ 53 651]]\n",
      "==================================================\n",
      "DecisionTreeClassifier Accuracy: 0.920778318276581\n",
      "Classification Report for DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92       735\n",
      "           1       0.86      1.00      0.92       704\n",
      "\n",
      "    accuracy                           0.92      1439\n",
      "   macro avg       0.93      0.92      0.92      1439\n",
      "weighted avg       0.93      0.92      0.92      1439\n",
      "\n",
      "Confusion Matrix for DecisionTreeClassifier:\n",
      "[[624 111]\n",
      " [  3 701]]\n",
      "==================================================\n",
      "GaussianNB Accuracy: 0.5830437804030577\n",
      "Classification Report for GaussianNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.69       735\n",
      "           1       0.72      0.24      0.36       704\n",
      "\n",
      "    accuracy                           0.58      1439\n",
      "   macro avg       0.64      0.58      0.53      1439\n",
      "weighted avg       0.64      0.58      0.53      1439\n",
      "\n",
      "Confusion Matrix for GaussianNB:\n",
      "[[668  67]\n",
      " [533 171]]\n",
      "==================================================\n",
      "XGBClassifier Accuracy: 0.906184850590688\n",
      "Classification Report for XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       735\n",
      "           1       0.86      0.96      0.91       704\n",
      "\n",
      "    accuracy                           0.91      1439\n",
      "   macro avg       0.91      0.91      0.91      1439\n",
      "weighted avg       0.91      0.91      0.91      1439\n",
      "\n",
      "Confusion Matrix for XGBClassifier:\n",
      "[[625 110]\n",
      " [ 25 679]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Define a list of classifiers\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "\n",
    "# Ensure there are no missing values in the training and testing datasets\n",
    "if np.any(np.isnan(X_train_scaled)) or np.any(np.isnan(X_test_scaled)):\n",
    "    print(\"Missing values detected. Imputing missing values...\")\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    \n",
    "    # Impute missing values with the mean\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_scaled = imputer.fit_transform(X_train_scaled)\n",
    "    X_test_scaled = imputer.transform(X_test_scaled)\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    try:\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{clf_name} Accuracy: {accuracy}\")\n",
    "        \n",
    "        # Classification report\n",
    "        print(f\"Classification Report for {clf_name}:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        print(f\"Confusion Matrix for {clf_name}:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(\"=\"*50)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error training {clf_name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c01d4",
   "metadata": {},
   "source": [
    "# Show Each Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9abac10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nofes\\AppData\\Local\\Temp\\ipykernel_12084\\3072346736.py:42: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'Model': clf_name, 'Accuracy': accuracy, 'F1-Score': f1_score,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.972203</td>\n",
       "      <td>0.972203</td>\n",
       "      <td>0.973049</td>\n",
       "      <td>0.972203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.651842</td>\n",
       "      <td>0.651286</td>\n",
       "      <td>0.654290</td>\n",
       "      <td>0.651842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.728978</td>\n",
       "      <td>0.728702</td>\n",
       "      <td>0.731320</td>\n",
       "      <td>0.728978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.658791</td>\n",
       "      <td>0.658830</td>\n",
       "      <td>0.659053</td>\n",
       "      <td>0.658791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.683113</td>\n",
       "      <td>0.683126</td>\n",
       "      <td>0.683656</td>\n",
       "      <td>0.683113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.787352</td>\n",
       "      <td>0.783833</td>\n",
       "      <td>0.812481</td>\n",
       "      <td>0.787352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.917304</td>\n",
       "      <td>0.916932</td>\n",
       "      <td>0.928074</td>\n",
       "      <td>0.917304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.583044</td>\n",
       "      <td>0.530092</td>\n",
       "      <td>0.635597</td>\n",
       "      <td>0.583044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.906185</td>\n",
       "      <td>0.905977</td>\n",
       "      <td>0.912148</td>\n",
       "      <td>0.906185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Accuracy  F1-Score  Precision    Recall\n",
       "0      RandomForestClassifier  0.972203  0.972203   0.973049  0.972203\n",
       "1          AdaBoostClassifier  0.651842  0.651286   0.654290  0.651842\n",
       "2  GradientBoostingClassifier  0.728978  0.728702   0.731320  0.728978\n",
       "3          LogisticRegression  0.658791  0.658830   0.659053  0.658791\n",
       "4                         SVC  0.683113  0.683126   0.683656  0.683113\n",
       "5        KNeighborsClassifier  0.787352  0.783833   0.812481  0.787352\n",
       "6      DecisionTreeClassifier  0.917304  0.916932   0.928074  0.917304\n",
       "7                  GaussianNB  0.583044  0.530092   0.635597  0.583044\n",
       "8               XGBClassifier  0.906185  0.905977   0.912148  0.906185"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define a list of classifiers\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'F1-Score', 'Precision', 'Recall'])\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    f1_score = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    \n",
    "    # Append results to DataFrame\n",
    "    # Append results to DataFrame\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([{'Model': clf_name, 'Accuracy': accuracy, 'F1-Score': f1_score, \n",
    "                                                       'Precision': precision, 'Recall': recall}])], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c700a81",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c4c4059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.9715079916608756\n",
      "Classification Report for Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       735\n",
      "           1       0.95      0.99      0.97       704\n",
      "\n",
      "    accuracy                           0.97      1439\n",
      "   macro avg       0.97      0.97      0.97      1439\n",
      "weighted avg       0.97      0.97      0.97      1439\n",
      "\n",
      "Confusion Matrix for Random Forest Classifier:\n",
      "[[699  36]\n",
      " [  5 699]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Instantiate the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classifier Accuracy:\", accuracy_rf)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report for Random Forest Classifier:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix for Random Forest Classifier:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf32e7",
   "metadata": {},
   "source": [
    "# Single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886f167e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  0\n",
      "actual class  0\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[10].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db84a339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  1\n",
      "actual class  1\n"
     ]
    }
   ],
   "source": [
    "# test 2:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[200].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89241591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  1\n",
      "actual class  1\n"
     ]
    }
   ],
   "source": [
    "# test 3:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[110].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[110])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc436e93",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3892cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rf_classifier,open(\"rf_classifier.pkl\",'wb'))\n",
    "pickle.dump(scaler,open(\"scaler.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96693443",
   "metadata": {},
   "source": [
    "# Load models to test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fc964d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the RandomForestClassifier model\n",
    "with open(\"rf_classifier.pkl\", \"rb\") as file:\n",
    "    rf_classifier = pickle.load(file)\n",
    "\n",
    "# Load the scaler\n",
    "with open(\"scaler.pkl\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19320175",
   "metadata": {},
   "source": [
    "# Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03d110d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(model, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose):\n",
    "    # Encode categorical variables\n",
    "    male_encoded = 1 if male.lower() == \"male\" else 0\n",
    "    currentSmoker_encoded = 1 if currentSmoker.lower() == \"yes\" else 0\n",
    "    BPMeds_encoded = 1 if BPMeds.lower() == \"yes\" else 0\n",
    "    prevalentStroke_encoded = 1 if prevalentStroke.lower() == \"yes\" else 0\n",
    "    prevalentHyp_encoded = 1 if prevalentHyp.lower() == \"yes\" else 0\n",
    "    diabetes_encoded = 1 if diabetes.lower() == \"yes\" else 0\n",
    "    \n",
    "    # Prepare features array\n",
    "    features = np.array([[male_encoded, age, currentSmoker_encoded, cigsPerDay, BPMeds_encoded, prevalentStroke_encoded, prevalentHyp_encoded, diabetes_encoded, totChol, sysBP, diaBP, BMI, heartRate, glucose]])\n",
    "\n",
    "    missing_feature_placeholder = 0\n",
    "    \n",
    "    # scalling\n",
    "    scaled_features = scaler.transform(features)\n",
    "\n",
    "    \n",
    "    # predict by model\n",
    "    result = model.predict(scaled_features)\n",
    "    \n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e3e5784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Patient has no Heart Desease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "male = \"female\"\n",
    "age = 56.00\n",
    "currentSmoker = \"yes\"\n",
    "cigsPerDay = 3.00\n",
    "BPMeds = \"no\"\n",
    "prevalentStroke = \"no\"\n",
    "prevalentHyp = \"yes\"\n",
    "diabetes = 'no'\n",
    "totChol = 285.00\n",
    "sysBP = 145.00\n",
    "diaBP = 100.00\n",
    "BMI = 30.14\n",
    "heartRate = 80.00\n",
    "glucose = 86.00\n",
    "\n",
    "\n",
    "result = predict(rf_classifier, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose)\n",
    "\n",
    "\n",
    "if result == 1:\n",
    "    print(\"The Patient has Heart Disease\")\n",
    "else: \n",
    "    print(\"The Patient has no Heart Desease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7bfbe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Patient has Heart Disease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#test2\n",
    "male = 'female'\n",
    "age = 63.0\n",
    "currentSmoker = 'yes'\n",
    "cigsPerDay = 3.0\n",
    "BPMeds = 'no'\n",
    "prevalentStroke = 'no'\n",
    "prevalentHyp = 'yes'\n",
    "diabetes = 'no'\n",
    "totChol = 267.0\n",
    "sysBP = 156.5\n",
    "diaBP = 92.5\n",
    "BMI = 27.1\n",
    "heartRate = 60.0\n",
    "glucose = 79.0\n",
    "result = 1.0\n",
    "\n",
    "\n",
    "\n",
    "result = predict(rf_classifier, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose)\n",
    "\n",
    "\n",
    "if result == 1:\n",
    "    print(\"The Patient has Heart Disease\")\n",
    "else: \n",
    "    print(\"The Patient has No Heart Desease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a8bf98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.1'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5131dba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 14)\n"
     ]
    }
   ],
   "source": [
    "# Define the input features array\n",
    "features = np.array([[1 if male.lower() == \"male\" else 0, age, 1 if currentSmoker.lower() == \"yes\" else 0, \n",
    "\t\t\t\t\t  cigsPerDay, 1 if BPMeds.lower() == \"yes\" else 0, 1 if prevalentStroke.lower() == \"yes\" else 0, \n",
    "\t\t\t\t\t  1 if prevalentHyp.lower() == \"yes\" else 0, 1 if diabetes.lower() == \"yes\" else 0, \n",
    "\t\t\t\t\t  totChol, sysBP, diaBP, BMI, heartRate, glucose]])\n",
    "\n",
    "print(features.shape)  # Should be (1, 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
